\documentclass[12pt,a4paper]{article}
\usepackage{times}
\usepackage{durhampaper}
\usepackage{harvard}

\citationmode{abbr}
\bibliographystyle{agsm}

\title{Image Processing using JavaScript and Web Assembly}
\author{} % leave; your name goes into \student{}
\student{Sam Robbins}
\supervisor{Tom Friedetzky}
\degree{BSc Computer Science}

\date{}

\begin{document}

\maketitle

\begin{abstract}
    \subsection{Context/Background}
    Web Assembly is a relatively new method for computation on the web, allowing for the use of a much wider range of languages. This is being used in high intensity contexts to improve computation time.

    \subsection{Aims}

    To determine in which cases implementing algorithms in web assembly is the right choice to make

    \subsection{Method}

    Implement a range of image processing algorithms in both JavaScript and Web Assembly and measure using a variety of metrics.

    \subsection{Results}

    \subsection{Conclusions}
\end{abstract}

\begin{keywords}
    Put a few keywords here.
\end{keywords}

\newpage

\section{Introduction}

Image processing is a widely used technique for a range of problems. In most modern cameras there will be some aspect of image processing at the time of capture, whether it is enhancements to the image or just the formatting to a file type, such as JPEG. After capture there is often additional image processing, be it applying filters or compression for upload online. Sophisticated image processing techniques don't just have benefit for the sharing of photos, but are also used medically, such as for processing CT images \cite{zhang2017applications}.

% Is it useful to go into more depth about the applications of image processing?

The performance of image processing was greatly improved with the introduction of Digital Signal Processors (DSP), these are specialised chips for performing signal processing tasks, such as the discrete cosine transform. In mobile devices these are now often integrated into the System on a Chip (SOC) \cite{angoletta2008digital}, however with the increase in computational performance since DSPs were introduced, these algorithms can also be ran on the main processor.

Traditionally image processing has been done in applications like Adobe Photoshop, however as browser market share is increasing web based photo editors are becoming more common. In a study by Forrester Consulting, workers are spending 1/3 of the work day on average in a web browser, so it is an area lots of companies are targeting to launch new products \cite{cloud_worker}.

% Look more into is it a good idea, not just if it's used

In 1995 JavaScript was introduced as a method for introducing interactivity to web applications, since then there were some improvements made for programmers who wanted to perform computationally intensive tasks with their website, such as Web Workers, introduced in 2009 \cite{Hickson}. However one of the biggest steps forward is the introduction of Web Assembly in 2017, allowing for assembly code to be executed by web browsers \cite{haas2017bringing}.

Using Web Assembly over JavaScript proposes advantages such as being able to use your existing codebase, rather than having to translate it into JavaScript along with benefits such as type safety using static types, where JavaScript uses dynamic types. TypeScript works to try and solve this problem, but is just a transpiler to JavaScript, where Web Assembly allows for type checking at runtime.

% Client vs Server based

\subsection{Objectives}

For this project I want to implement a range of image processing algorithms in both Web Assembly and JavaScript and compare their performance. For Web Assembly I will be using the Rust programming language as it is one of the most popular languages for web assembly and contains a range of features to make creating web assembly easier.

% This needs more detail

\subsection{Research Question}

My Research question is to find in which cases Web Assembly offers a benefit over JavaScript, finding this out by implementing image processing algorithms using both mechanisms.

\newpage


\section{Related Work}

\subsection{Language options for web assembly}

\subsection{Web Assembly Image Processing in use}

Squoosh by Google Chrome is a tool to compress images and implements many of its codecs using Web Assembly, this approach was also adopted by Next.js for their image component to improve performance, reducing the installed size by 27.3 MB \cite{nextjs}. As this was replacing a package with code in the project, it led to a large increase in the amount of code to maintain, but this could be abstracted to a package. One example of such a package is \texttt{photon} which provides abstractions on top of the \texttt{image} Rust library \cite{photon}.

% Add comparison for the 27MB as to what the overall size is
% Clarify all

\subsection{Performance of Web Assembly}

Alongside image processing, Web Assembly is also used for a range of other purposes. Figma is a tool for designers, and implemented Web Assembly to improve their load times 3$\times$ compared to their previous solution which translated assembly to JavaScript \cite{figmawasm}.

% Why are load times important

However, web assembly is not always the best solution, as when the same author was creating a JavaScript bundler they recommend against using Web Assembly \cite{esbuild}. This is because JavaScript bundlers are ran natively on the computer, rather than in a browser, a method enabled by solutions such as Node.js. Node.js has very similar performance to browsers as it uses the same v8 browser engine as Google Chrome does, however Node.js also means that native code can be ran, which the author observed to provide a 10$\times$ speed up.

% Add detail of what a JavaScript bundler is

This behaviour was also observed in \cite{jangda2019not}, where peak slowdowns were observed of 2.5$\times$ in Google Chrome compared to the native code. These benchmarks are taken from SPEC CPU2006 and SPEC CPU2017. A sample of these results are shown in Table \ref{native}

\begin{table}[htb]
    \centering
    \caption{Comparison of algorithms between native and wasm}
    \vspace*{6pt}
    \label{native}
    \begin{tabular}{cccc}\hline\hline
        Benchmark & Field                   & Native execution time & Google Chrome execution time \\ \hline
        bzip2     & Compression             & 370                   & 864                          \\
        mcf       & Combinatorial           & 221                   & 180                          \\
        milc      & Chromodynamics          & 375                   & 369                          \\
        namd      & Molecular Dynamics      & 271                   & 369                          \\
        gobmk     & Artificial Intelligence & 352                   & 537
    \end{tabular}
\end{table}

As one can see from these results, Native isn't guaranteed to be faster than Web Assembly, however this is often the case.



\newpage
\subsection{Current Image Processing Techniques}

One of the most popular image processing libraries for JavaScript is Sharp with over 1,700,000 weekly downloads, this uses native code in the form of libvips and claims to be the fastest module for resizing. A slightly less popular library is jimp with over 1,400,000 weekly downloads, the difference with this library is that it is written entirely in JavaScript and so can be ran in the browser. The difference between these and other libraries was measured on a task of resizing an image \cite{sharp}. These results are shown in Table \ref{imgproc}

\begin{table}[htb]
    \centering
    \caption{Performance of Image Processing Libraries}
    \vspace*{6pt}
    \label{imgproc}
    \begin{tabular}{ccc}\hline\hline
        Library     & Best ops/sec & Best speedup \\ \hline
        jimp        & 0.77         & 1.0          \\
        mapnik      & 3.39         & 4.4          \\
        gm          & 4.33         & 5.6          \\
        imagemagick & 4.39         & 5.7          \\
        sharp       & 25.60        & 33.2
    \end{tabular}
\end{table}

% Add description of what the table headings mean

This shows native libraries being significantly faster than the solution in pure JavaScript, which means that even with the slowdown of web assembly compared to native code as discussed before, web assembly should still outperform JavaScript in this regard.

\subsection{Image formats}

There are a range of image formats in use, and the encoding and decoding of images is a computationally intensive task. The Web Almanac studies over 7 million websites and found that 40.26\% of images are of the jpg image format and 26.90\% in png \cite{webalmanac}. JPEG is a high performance image codec with a study by Cloudinary showing to to have an encoding speed of 49 MP/s and a decoding speed of 108 MP/s \cite{cloudinary}. JPEG has both lossless and lossy versions, and in a study of lossless compression of 382 images, these results are shown in Table \ref{speedratio} \cite{ukrit2011survey}

% Add more details of what hardware this was one
% Don't include numbers if you don't have comparison

\begin{table}[htb]
    \centering
    \caption{Compression speed and ratio for various algorithms}
    \vspace*{6pt}
    \label{speedratio}
    \begin{tabular}{ccc}\hline\hline
        Algorithm     & Compression Speed & Compression Ratio \\ \hline
        Lossless JPEG & 11.9              & 3.04              \\
        JPEG-LS       & 19.6              & 4.21              \\
        JPEG 2000     & 4.0               & 3.79              \\
        PNG           & 3.6               & 3.35              \\
    \end{tabular}
\end{table}

As one can see from these results, the compression ratio is very comparable between the various implementations of JPEG and PNG, however the compression speed greatly differs, with some JPEG algorithms significantly outperforming PNG.

\newpage

\section{Solution}

This section presents the solutions to the problems in detail.  The design and implementation details should all be placed in this section.  You may create a number of subsections, each focussing on one issue.

This section should be between 4 to 7 pages in length.
\newpage
\section{Results}

this section presents the results of the solutions.  It should include information on experimental settings.  The results should demonstrate the claimed benefits/disadvantages of the proposed solutions.

This section should be between 2 to 3 pages in length.
\newpage
\section{Evaluation}

This section should between 1 to 2 pages in length.
\newpage
\section{Conclusions}

This section summarises the main points of this paper.  Do not replicate the abstract as the conclusion.  A conclusion might elaborate on the importance of the work or suggest applications and extensions.  This section should be no more than 1 page in length.

The page lengths given for each section are indicative and will vary from project to project but should not exceed the upper limit.  A summary is shown in Table \ref{summary}.

\begin{table}[htb]
    \centering
    \caption{SUMMARY OF PAGE LENGTHS FOR SECTIONS}
    \vspace*{6pt}
    \label{summary}
    \begin{tabular}{|ll|c|} \hline
             & \multicolumn{1}{c|}{\bf Section} & {\bf Number of Pages} \\ \hline
        I.   & Introduction                     & 2--3                  \\ \hline
        II.  & Related Work                     & 2--3                  \\ \hline
        III. & Solution                         & 4--7                  \\ \hline
        IV.  & Results                          & 2--3                  \\ \hline
        V.   & Evaluation                       & 1-2                   \\ \hline
        VI.  & Conclusions                      & 1                     \\ \hline
    \end{tabular}
\end{table}

\newpage
\bibliography{projectpaper}


\end{document}